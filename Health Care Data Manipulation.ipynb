{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60fe4938",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.options.display.float_format = '{:,.2f}'.format  # set other global format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419d7fc7",
   "metadata": {},
   "source": [
    "<b> Reading the file </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9eb67627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the Trade Atlas Indonesia File\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None) \n",
    "print('Reading the Trade Atlas Indonesia File')\n",
    "df=pd.read_excel(\"C:/Users/DrC/Desktop/Eureka Idea Co/Number of Test Testing File/Indonesia 2021-Including Exchange Rates WA V2_Updated with Verification.xlsx\",sheet_name='Indonesia 2021-Indonesia 2021V1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a32cb8d",
   "metadata": {},
   "source": [
    "<b>Data cleaning </b>\n",
    "- Removing starting and trailing spaces\n",
    "- Removing the identified terms\n",
    "- Removing punctuation\n",
    "- Removing double spaces\n",
    "- Adding Keywords as columns in the dataframe. These columns are used as indicators/boolean checks for the presence of keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e87c57f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing Product Details Column for the extraction of number of tests\n"
     ]
    }
   ],
   "source": [
    "df1=df\n",
    "print('Preparing Product Details Column for the extraction of number of tests')\n",
    "#Adding the keywards to the pandas dataframe\n",
    "Keyword_list=['T','TES','TEST','BOX','CASSETTES','RXN','RNX','REACTION','KIT','PCS','PCE','STRIP']\n",
    "df1 = df1.reindex(columns = df1.columns.tolist() + Keyword_list) #Adding empty columns to the python list \n",
    "\n",
    "#PDC CLEANING\n",
    "df1['PDC']=df['PRODUCT DETAILS'] #NEW COLUMN PDC (Product Details Cleaning) has the the product detail data in it now.\n",
    "\n",
    "#Removing starting and trailing spaces\n",
    "df1['PDC']= df1['PDC'].str.strip() #\n",
    "\n",
    "#Remove COVID-19 OR COVID 19 from the string\n",
    "df1['PDC']= df1['PDC'].str.replace('COVID-19', ' ', case = False)\n",
    "df1['PDC']= df1['PDC'].str.replace('COVID 19', ' ', case = False)\n",
    "df1['PDC']= df1['PDC'].str.replace(' COVID 19 ', ' ', case = False)\n",
    "df1['PDC']= df1['PDC'].str.replace('COVID -19', ' ', case = False)\n",
    "df1['PDC']= df1['PDC'].str.replace('COVID- 19', ' ', case = False) \n",
    "df1['PDC']= df1['PDC'].str.replace('COVID TEST 19', ' ', case = False) \n",
    "df1['PDC']= df1['PDC'].str.replace('QUANT 20', ' ', case = False) \n",
    "df1['PDC']= df1['PDC'].str.replace('POCKIT', ' ', case = False) \n",
    "df1['PDC']= df1['PDC'].str.replace('1KIT', ' ', case = False) \n",
    "df1['PDC']= df1['PDC'].str.replace('SCNTH', ' ', case = False) \n",
    "df1['PDC']= df1['PDC'].str.replace('SCNTL', ' ', case = False) \n",
    "df1['PDC']= df1['PDC'].str.replace('DETECTION KIT', ' ', case = False) \n",
    "df1['PDC']= df1['PDC'].str.replace('EAR99', ' ', case = False) \n",
    "\n",
    " \n",
    "#Remove COV-2 related keywords from the string\n",
    "df1['PDC']= df1['PDC'].str.replace('COV-2', ' ', case = False)\n",
    "df1['PDC']= df1['PDC'].str.replace('COV 2', ' ', case = False)\n",
    "df1['PDC']= df1['PDC'].str.replace('COV2', ' ', case = False)\n",
    "\n",
    "\n",
    "#Remove VAR-2 from the string\n",
    "df1['PDC']= df1['PDC'].str.replace('VAR2', ' ', case = False) #SOLVES THE ISSUE \n",
    "\n",
    "#Remove SARS COV 2 related keywords from the string\n",
    "df1['PDC']= df1['PDC'].str.replace('SARS COV 2', ' ', case = False) #SOLVES THE ISSUE \n",
    "df1['PDC']= df1['PDC'].str.replace('SARS-COV-2', ' ', case = False) #SOLVES THE ISSUE \n",
    "df1['PDC']= df1['PDC'].str.replace('SARSCOV3', ' ', case = False) #SOLVES THE ISSUE \n",
    "\n",
    "#Remove the punctuation and the brackets. \n",
    "df1['PDC'] = df1['PDC'].str.replace(r'[^\\w\\s]+', '') \n",
    "\n",
    "#Removing double spaces between the words\n",
    "df1['PDC']= df1['PDC'].replace('\\s+', ' ', regex=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff53dc6f",
   "metadata": {},
   "source": [
    "<b> Checking presence of keywords in every row of product details </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e284af44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking presence of keywords in every row of product details  \n",
    "for x in range(0,len(df1['PDC'])):\n",
    "    for y in range(0,len(Keyword_list)):\n",
    "        if(Keyword_list[y]!='T'):\n",
    "            if(Keyword_list[y] in df1['PDC'][x]):\n",
    "                df1[Keyword_list[y]][x]=1\n",
    "            else:\n",
    "                df1[Keyword_list[y]][x]=0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0217a7a3",
   "metadata": {},
   "source": [
    "<b> Splitting the product detail column in to words </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0c76c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Product Details Column for the extraction of number of tests\n"
     ]
    }
   ],
   "source": [
    "print('Processing Product Details Column for the extraction of number of tests')\n",
    "\n",
    "#Splitting the product detail column in to words\n",
    "df1['PDC_SPLIT']=df1['PDC'].str.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6f5e26",
   "metadata": {},
   "source": [
    "<b> Checking the presence of T </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53baf13e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Checking the presence of T in the split words\n",
    "for x in range(0,len(df1['PDC'])):\n",
    "    for y in range(0,len(df1['PDC_SPLIT'][x])):\n",
    "        if(df1['PDC_SPLIT'][x][y]=='T'):\n",
    "            df1['T'][x]=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17389ed4",
   "metadata": {},
   "source": [
    "<b>Checking if the word contains a digit</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7be4e8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def containsNumber(value):\n",
    "    for character in value:\n",
    "        if character.isdigit():\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e287d6fa",
   "metadata": {},
   "source": [
    "<b>Creating a column \"words\" that has words from the product detail split column containing digits or a combination of digits or characters.  </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51683a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a column with an empty list\n",
    "df1['words'] = np.empty((len(df1), 0)).tolist()\n",
    "#Taking the values from the PDC split that has numbers only. \n",
    "for i in range(0,len(df1['PDC_SPLIT'])):\n",
    "    for w in range(0,len(df1['PDC_SPLIT'][i])):\n",
    "    \n",
    "        if(containsNumber(df1['PDC_SPLIT'][i][w])==True):#if conition if the word contains a digit\n",
    "            df1['words'][i].append(df1['PDC_SPLIT'][i][w]) #appending the list with words that have number in it\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e806275",
   "metadata": {},
   "source": [
    "<b>A new column is generated called refined words. Words that gets in to this column meets the following conditions:</b> <br>\n",
    "1.There is a digit present and the number is than 2500 <br>\n",
    "2. The keyword is present with the number.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c167e192",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['refined_words'] = np.empty((len(df1), 0)).tolist()\n",
    "#selecting only the words that contain numbers\n",
    "for x in range(0,len(df1['words'])):\n",
    "    for y in range(0,len(df1['words'][x])):\n",
    "        if((df1['words'][x][y].isdigit() and int(df1['words'][x][y])<=2500)  or ('T' in df1['words'][x][y]) or ('RXN' in df1['words'][x][y]) or ('PCE' in df1['words'][x][y]) or ('EA' in df1['words'][x][y]) or ('CASSE' in df1['words'][x][y]) or ('BOX' in df1['words'][x][y]) or ('PCS' in df1['words'][x][y]) or ('KIT' in df1['words'][x][y]) or ('TES' in df1['words'][x][y]) or ('STRIP' in df1['words'][x][y])):\n",
    "            df1['refined_words'][x].append(df1['words'][x][y]) \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd319e0",
   "metadata": {},
   "source": [
    "<b>A Column for Manual Verification</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76572c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['REQUIRES_MANUAL_VERIFICATION']=''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e049930f",
   "metadata": {},
   "source": [
    "<b>Following conditions are implemented in the code below: </b>\n",
    "1) if the refined words only contain the numbers then check the range of the numbers. If it is >=5 and <=2500 then we take it as valid test. <br> \n",
    "2) if the refine words column contain numbers only and all are equal, then we remove the duplicates and get one value only. <br> \n",
    "3) If the number of refined words column has one value and contains digit with characters then check if it has a keyword attached to it. If yes, then take that number. <Br> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15d46150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product Details column processing completed\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "df1['test_quantity'] = np.empty((len(df1), 0)).tolist()\n",
    " \n",
    "df1=df1.fillna(0)\n",
    "for x in range(0,len(df1['refined_words'])):\n",
    "    for y in range(0,len(df1['refined_words'][x])):\n",
    "        res=all(map(str.isdigit, df1['refined_words'][x])) #all the elements in the list are digit only- return true\n",
    "        if(res==True and len(df1['refined_words'][x])!=0):  #checking that the list contain all the numbers only\n",
    "            if(int(df1['refined_words'][x][y])>=5 and int(df1['refined_words'][x][y])<=2500): #Sanity range taken to be greater than 5 and less than 2500\n",
    "                df1['test_quantity'][x].append(re.sub(\"[^0-9]\", \"\", df1['refined_words'][x][y]))\n",
    "        result_equal = all(element == df1['refined_words'][x][0] for element in df1['refined_words'][x]) #if all the elements in the list are equal\n",
    "        if(result_equal==True and len(df1['refined_words'][x])>1 and res==True): #only digits lists being handled uptil now\n",
    "            df1['test_quantity'][x]=np.unique(np.array(df1['refined_words'][x])).tolist() #converting to list back again \n",
    "     \n",
    "        \n",
    "        #list contains only one value and that value is a number with characters\n",
    "        elif(len(df1['refined_words'][x])==1 and int(re.sub(\"[^0-9]\", \"\", df1['refined_words'][x][y]))>5 and int(re.sub(\"[^0-9]\", \"\", df1['refined_words'][x][y])) and res==False):  #if length is one then remove the characters and insert the digits\n",
    "         \n",
    "            if(('T' in df1['refined_words'][x][y])):\n",
    "                count_t = df1['refined_words'][x][y].count('T')\n",
    "                if(count_t==1 or count_t==2 or count_t==3 or count_t==4):\n",
    "                    df1['T'][x]=1   #This T condition is just for the boolean check\n",
    "                    df1['test_quantity'][x].append(re.sub(\"[^0-9]\", \"\", df1['refined_words'][x][y])) \n",
    "                    \n",
    "            else:\n",
    "                df1['test_quantity'][x].append(re.sub(\"[^0-9]\", \"\", df1['refined_words'][x][y]))\n",
    "\n",
    "              \n",
    "        elif(len(df1['refined_words'][x])>1 and res==False): #if any of the word contains the keyword then we need that value only.\n",
    "            if((('TE' in df1['refined_words'][x][y]) or ('KIT' in df1['refined_words'][x][y]) or ('RXN' in df1['refined_words'][x][y]) or ('PCS' in df1['refined_words'][x][y]) or ('PCE' in df1['refined_words'][x][y]) or ('CASSE' in df1['refined_words'][x][y]) or ('BOX' in df1['refined_words'][x][y]) or ('RNX' in df1['refined_words'][x][y]) or ('STRIP' in df1['refined_words'][x][y]) ) and ((int(re.sub(\"[^0-9]\", \"\", df1['refined_words'][x][y]))>=5) and int(re.sub(\"[^0-9]\", \"\", df1['refined_words'][x][y]))<=2500)):\n",
    "                if(int(re.sub(\"[^0-9]\", \"\", df1['refined_words'][x][y]))>=5 and int(re.sub(\"[^0-9]\", \"\", df1['refined_words'][x][y]))<=2500):\n",
    "                    df1['test_quantity'][x].append(re.sub(\"[^0-9]\", \"\", df1['refined_words'][x][y]))\n",
    "           \n",
    "            \n",
    "            \n",
    "            elif(('T' in df1['refined_words'][x][y])):\n",
    "             \n",
    "                count_t = df1['refined_words'][x][y].count('T')\n",
    "                if(count_t==1): #not taking count t==2 because there are more than one words and it may cause confusion\n",
    "                    if(int(re.sub(\"[^0-9]\", \"\", df1['refined_words'][x][y]))>=5 and int(re.sub(\"[^0-9]\", \"\", df1['refined_words'][x][y]))<=2500):\n",
    "                        df1['test_quantity'][x].append(re.sub(\"[^0-9]\", \"\", df1['refined_words'][x][y])) \n",
    "                        df1['T'][x]=1\n",
    "                        \n",
    "print('Product Details column processing completed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a64ec99",
   "metadata": {},
   "source": [
    "<b> Boolean Checks / Indicators </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a75bf716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Boolean checks for the presence of Keywords\n",
      "Boolean checks created\n",
      "Number of tests extracted from Product details\n"
     ]
    }
   ],
   "source": [
    "print('Creating Boolean checks for the presence of Keywords')\n",
    "\n",
    "r = re.compile(r'([0-9]+X[0-9]+T+|[0-9]+\\*[0-9]+T|[0-9]+\\*[0-9]+ T|[0-9]+X[0-9]+ T+)') #Regex for identifying Multiplication values\n",
    "#Creating Keywords boolean checks.\n",
    "df1['test_quantity_final'] = np.empty((len(df1), 0)).tolist()\n",
    "df1['Auto_Data_Quality_index']=\"\"\n",
    "boolean_counter=0\n",
    "for x in range(0,len(df1['refined_words'])): #can use any column just need to get the length\n",
    "    for y in range(0,len(Keyword_list)):\n",
    "        if (df1[Keyword_list[y]][x]==1):\n",
    "             boolean_counter=boolean_counter+1\n",
    "            \n",
    "    \n",
    "    if(boolean_counter>=1 and len(df1['test_quantity'][x])==1):\n",
    "        \n",
    "        df1['test_quantity_final'][x]=int(df1['test_quantity'][x][0])\n",
    "        df1['Auto_Data_Quality_index'][x]='Keyword and Value both are present'\n",
    "    \n",
    "    if(boolean_counter>=1 and len(df1['test_quantity'][x])>1):\n",
    "        df1['test_quantity_final'][x]=np.nan\n",
    "        df1['Auto_Data_Quality_index'][x]='Keyword and Two Values are present'\n",
    "        df1['REQUIRES_MANUAL_VERIFICATION'][x]=1\n",
    "        \n",
    "    if(boolean_counter==0):\n",
    "        df1['test_quantity_final'][x]=1\n",
    "        df1['Auto_Data_Quality_index'][x]='No Keyword present'\n",
    "        \n",
    "    if(boolean_counter>=1 and len(df1['test_quantity'][x])==0):\n",
    "        df1['test_quantity_final'][x]=1\n",
    "        df1['Auto_Data_Quality_index'][x]='Keyword found but no value'\n",
    "    #This condition shall stay in the last\n",
    "    if(df1['test_quantity_final'][x]>2500):\n",
    "        df1['test_quantity_final'][x]=1\n",
    "    boolean_counter=0\n",
    "    \n",
    "    if(r.search(df1['PRODUCT DETAILS'][x])):\n",
    "        df1['test_quantity_final'][x]=np.nan\n",
    "        df1['Auto_Data_Quality_index'][x]='Multiplication Values'\n",
    "        df1['REQUIRES_MANUAL_VERIFICATION'][x]=1\n",
    "\n",
    "print('Boolean checks created')\n",
    "print('Number of tests extracted from Product details')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e176280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Keyword present                    710\n",
      "Keyword found but no value            603\n",
      "Keyword and Value both are present    479\n",
      "Keyword and Two Values are present     12\n",
      "Multiplication Values                   8\n",
      "Name: Auto_Data_Quality_index, dtype: int64\n",
      "Auto Data Quality index created\n"
     ]
    }
   ],
   "source": [
    "#Value counts for the Auto Data Quality Index \n",
    "df1['Auto_Data_Quality_index'].value_counts()\n",
    "print(df1['Auto_Data_Quality_index'].value_counts())\n",
    "print('Auto Data Quality index created')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d07a93",
   "metadata": {},
   "source": [
    "# NEW TASKS TO DO "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99edc4b3",
   "metadata": {},
   "source": [
    "1) Categorize the product detail in to RDT AND NON RDT.  The keywords are in the methodology file. We are concerned for RDT (Antigen & Antibody). There should a column which specifies the product detail is RDT or Non RDT. <BR>\n",
    "2) Convert the currency in to USD (based on specific dates) and multiply the import value.<BR>\n",
    "3) We need to get the top 80% data for the RDT. Arrange the data in descending order and then get the top 80%. (Percentile) <BR>\n",
    "4) Filter calibration unit and control units"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea45054d",
   "metadata": {},
   "source": [
    "<B>1) Categorize the product detail in to RDT AND NON RDT. </B>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fd02bf",
   "metadata": {},
   "source": [
    "a) Filter All product Details that have \"Pcr\" in it and Marks them as \"Non-RDT\". Mark them as \"Last Data Quality Step\" = 1 <br>\n",
    "b) Filter All product Details that have \"Antigen\" in it and Marks them as \"SARS-CoV-2 Antigen Rapid Diagnostic Tests\" in the \"Test Type\" Column.<br>\n",
    "c) Filter All product Details that have \" Ag \", \"Ag \" and \" Ag\" in it and Marks them as \"SARS-CoV-2 Antigen Rapid Diagnostic Tests\" in the \"Test Type\" Column.<br>\n",
    "d) Filter All product Details that have \"antibod\" in it and Marks them as \"SARS-CoV-2 Antibody Rapid Diagnostic Tests\" in the \"Test Type\" Column.<br>\n",
    "e) Filter All product Details that have \"igg\" in it and Marks them as \"SARS-CoV-2 Antibody Rapid Diagnostic Tests\" in the \"Test Type\" Column.<br>\n",
    "f) Filter All product Details that have \"igm\" in it and Marks them as \"SARS-CoV-2 Antibody Rapid Diagnostic Tests\" in the \"Test Type\" Column.<br>\n",
    "g) Filter \"Blanks\" in test types. We are not sure about these products. Primarily we can assume that these are also Non-RDT, Non-PCR, Mark them as \"Non-RDT, Non PCR\" in the test Type<br>\n",
    "h) Now select \"SARS-CoV-2 Antigen Rapid Diagnostic Tests\" and \"SARS-CoV-2 Antibody Rapid Diagnostic Tests\" from Test Types. These are the only considerable products that require manual verification for data Quality Index.<br>\n",
    "i) Filter Product Details with \"CAL \" and mark them as \"Calibration Unit\" <br>\n",
    "j) Filter \"Number of Tests/Box\" column with \"2*XXX\" and Similar values and mark them as \"Calibration + Test Kit\" Put value in Manual Entry Number of tests/Box. For 2x100, put 100 (i.e. 100 tests and 100 Calibration unit)<br>\n",
    "k) Filter Product Details with \"CTL \" and mark them as \"Control Unit\" <br>\n",
    "l) Filter \"Number of Tests/Box\" column with \"2*XXX\" and Similar values and mark them as \"Calibration + Test Kit\" Put value in Manual Entry Number of tests/Box. For 2x100, put 100 (i.e. 100 tests and 100 Control unit)<br>\n",
    "m) Filter Product Details with \"CONT\" and mark them as \"Control Unit\"<br>\n",
    "n) Filter Product Details with Text Filter Contains \"Quant*CO\" and mark them as \"Control Unit\" <br>\n",
    "o) Filter Product Details with Text Filter Contains \"Quant*CA\" and mark them as \"Calibration Unit\" <br>\n",
    "p) Filter with \"MGM\" in the \"Quantity Unit\" Column and Mark them as Non-RDT  <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c21b73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Test_Type'] = np.empty((len(df1), 0)).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2f85ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labelling Non RDT products\n"
     ]
    }
   ],
   "source": [
    "#a) Filter All product Details that have \"Pcr\" in it and Marks them as \"Non-RDT\". Mark them as \"Last Data Quality Step\" = 1 \n",
    "#m) Filter Product Details with \"CONT\" and mark them as \"Control Unit\"\n",
    "#n) Filter Product Details with Text Filter Contains \"QuantCO\" and mark them as \"Control Unit\"\n",
    "#o) Filter Product Details with Text Filter Contains \"QuantCA\" and mark them as \"Calibration Unit\"\n",
    "\n",
    "print('Labelling Non RDT products')\n",
    "non_rdt=['PCR', 'CONT','CAL','CTL','QUANTCO','QUANTCA','QUANT CA', 'QUANT CO']\n",
    "\n",
    "for x in range(0,len(df1['PRODUCT DETAILS'])):\n",
    "    for y in range(0,len(non_rdt)):\n",
    "        if(non_rdt[y] in df1['PRODUCT DETAILS'][x]):\n",
    "            df1['Test_Type'][x].append('Non-RDT') \n",
    "    \n",
    "    df1['Test_Type'][x]=np.unique(np.array(df1['Test_Type'][x])).tolist()\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f7f20a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labelling Antigen products\n"
     ]
    }
   ],
   "source": [
    "# b) Filter All product Details that have \"Antigen\" in it and Marks them as \"SARS-CoV-2 Antigen Rapid Diagnostic Tests\" in the \"Test Type\" Column.\n",
    "# c) Filter All product Details that have \" Ag \", \"Ag \" and \" Ag\" in it and Marks them as \"SARS-CoV-2 Antigen Rapid Diagnostic Tests\" in the \"Test Type\" Column.\n",
    "\n",
    "print('Labelling Antigen products')\n",
    "\n",
    "antigen = [\"ANTIGEN\", \" AG \", \"AG \", \" AG\"]\n",
    "\n",
    "\n",
    "#Performing the Boolean check\n",
    "for x in range(0,len(df1['PRODUCT DETAILS'])):\n",
    "    for y in range(0,len(antigen)):\n",
    "        if(antigen[y] in df1['PRODUCT DETAILS'][x]):\n",
    "            df1['Test_Type'][x].append('SARS-CoV-2 Antigen Rapid Diagnostic Tests') \n",
    "    \n",
    "    df1['Test_Type'][x]=np.unique(np.array(df1['Test_Type'][x])).tolist()\n",
    "\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7cb5fbf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labelling Antibody products\n"
     ]
    }
   ],
   "source": [
    "#Filter All product Details that have \"antibod\" in it and Marks them as \"SARS-CoV-2 Antibody Rapid Diagnostic Tests\" in the \"Test Type\" Column.<br>\n",
    "#Filter All product Details that have \"igg\" in it and Marks them as \"SARS-CoV-2 Antibody Rapid Diagnostic Tests\" in the \"Test Type\" Column.<br>\n",
    "#Filter All product Details that have \"igm\" in it and Marks them as \"SARS-CoV-2 Antibody Rapid Diagnostic Tests\" in the \"Test Type\" Column.<br>\n",
    "\n",
    "\n",
    "print('Labelling Antibody products')\n",
    "\n",
    "antibody=['ANTIBOD','IGG', 'IGM']\n",
    "\n",
    "#Performing the Boolean check\n",
    "for x in range(0,len(df1['PRODUCT DETAILS'])):\n",
    "    for y in range(0,len(antibody)):\n",
    "        if(antibody[y] in df1['PRODUCT DETAILS'][x]):\n",
    "            df1['Test_Type'][x].append('SARS-CoV-2 Antibody Rapid Diagnostic Tests') \n",
    "    \n",
    "    df1['Test_Type'][x]=np.unique(np.array(df1['Test_Type'][x])).tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d47cd9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labelling Non RDT and Non PCR\n"
     ]
    }
   ],
   "source": [
    "#Filter \"Blanks\" in test types. We are not sure about these products. \n",
    "#Primarily we can assume that these are also Non-RDT, Non-PCR, Mark them as \"Non-RDT, Non PCR\" in the test Type\n",
    "\n",
    "\n",
    "print('Labelling Non RDT and Non PCR')\n",
    "\n",
    "for x in range(0,len(df1['Test_Type'])):\n",
    "    if(len(df1['Test_Type'][x])==0):\n",
    "        df1['Test_Type'][x].append('Non-RDT, Non PCR')    \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ac3df6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing the list brackets\n",
    "df1['Test_Type'] = df1['Test_Type'].str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8692d14e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                 Non-RDT, Non PCR\n",
       "1                                 Non-RDT, Non PCR\n",
       "2                                          Non-RDT\n",
       "3                                 Non-RDT, Non PCR\n",
       "4                                 Non-RDT, Non PCR\n",
       "                           ...                    \n",
       "1807     SARS-CoV-2 Antigen Rapid Diagnostic Tests\n",
       "1808    SARS-CoV-2 Antibody Rapid Diagnostic Tests\n",
       "1809     SARS-CoV-2 Antigen Rapid Diagnostic Tests\n",
       "1810                              Non-RDT, Non PCR\n",
       "1811                                       Non-RDT\n",
       "Name: Test_Type, Length: 1812, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Test_Type']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f09ea0",
   "metadata": {},
   "source": [
    "<b>Missing</b> <br> \n",
    "1) Filter \"Number of Tests/Box\" column with \"2*XXX\" and Similar values and mark them as \"Calibration + Test Kit\" Put value in Manual Entry Number of tests/Box. For 2x100, put 100 (i.e. 100 tests and 100 Calibration unit)<br>\n",
    "2) Filter \"Number of Tests/Box\" column with \"2*XXX\" and Similar values and mark them as \"Calibration + Test Kit\" Put value in Manual Entry Number of tests/Box. For 2x100, put 100 (i.e. 100 tests and 100 Control unit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89090a39",
   "metadata": {},
   "source": [
    "# h) Now select \"SARS-CoV-2 Antigen Rapid Diagnostic Tests\" and \"SARS-CoV-2 Antibody Rapid Diagnostic Tests\" from Test Types. These are the only considerable products that require manual verification for data Quality Index. <BR>\n",
    "    \n",
    " ASK THIS: p) Filter with \"MGM\" in the \"Quantity Unit\" Column and Mark them as Non-RDT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9539f59",
   "metadata": {},
   "source": [
    "# Converting the Price Value in to USD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1c775672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the Exchange Rate file\n"
     ]
    }
   ],
   "source": [
    "#Reading the exchange rate sheet\n",
    "print('Reading the Exchange Rate file')\n",
    "er=pd.read_excel(\"C:/Users/DrC/Desktop/Eureka Idea Co/Number of Test Testing File/Indonesia 2021-Including Exchange Rates WA V2_Updated with Verification.xlsx\",sheet_name='Exchange rates')\n",
    "er=er.iloc[:,0:10]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b770d3b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>USD</th>\n",
       "      <th>IDR</th>\n",
       "      <th>JPY</th>\n",
       "      <th>CNY</th>\n",
       "      <th>AUD</th>\n",
       "      <th>GBP</th>\n",
       "      <th>EUR</th>\n",
       "      <th>SGD</th>\n",
       "      <th>VND</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-03-16</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.23</td>\n",
       "      <td>1.12</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-03-17</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.21</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-03-18</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.19</td>\n",
       "      <td>1.09</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-03-19</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.58</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.08</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-03-20</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.18</td>\n",
       "      <td>1.07</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  USD  IDR  JPY  CNY  AUD  GBP  EUR  SGD  VND\n",
       "0 2020-03-16 1.00 0.00 0.01 0.14 0.61 1.23 1.12 0.70 0.00\n",
       "1 2020-03-17 1.00 0.00 0.01 0.14 0.60 1.21 1.10 0.70 0.00\n",
       "2 2020-03-18 1.00 0.00 0.01 0.14 0.59 1.19 1.09 0.69 0.00\n",
       "3 2020-03-19 1.00 0.00 0.01 0.14 0.58 1.16 1.08 0.69 0.00\n",
       "4 2020-03-20 1.00 0.00 0.01 0.14 0.59 1.18 1.07 0.69 0.00"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "er.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b6e83ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting datetime to date \n",
    "df1['Date'] = pd.to_datetime(df1['ARRIVAL DATE']).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "23e8473d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Date']=df1['Date'].astype('datetime64[ns]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cf9b8aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.merge(er, on='Date', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "75cd3ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting Import Value CIF to USD\n"
     ]
    }
   ],
   "source": [
    "#CURRENCY CONVERSION\n",
    "\n",
    "print('Converting Import Value CIF to USD')\n",
    "df1[\"IMPORT_VALUE_CIF_USD\"] = np.NaN\n",
    "df1['IMPORT VALUE CIF']=df1['IMPORT VALUE CIF'].astype(float)\n",
    "\n",
    "for x in range(0,len(df1['IMPORT VALUE CIF'])):\n",
    "    if(df1['CURRENCY'][x]=='USD'):\n",
    "        df1['IMPORT_VALUE_CIF_USD'][x]=df1['IMPORT VALUE CIF'][x]*df1['USD'][x]\n",
    "        \n",
    "    elif(df1['CURRENCY'][x]=='IDR'):\n",
    "        df1['IMPORT_VALUE_CIF_USD'][x]=df1['IMPORT VALUE CIF'][x]*df1['IDR'][x]\n",
    "        \n",
    "    elif(df1['CURRENCY'][x]=='JPY'):\n",
    "        df1['IMPORT_VALUE_CIF_USD'][x]=df1['IMPORT VALUE CIF'][x]*df1['JPY'][x]\n",
    "        \n",
    "    elif(df1['CURRENCY'][x]=='CNY'):\n",
    "        df1['IMPORT_VALUE_CIF_USD'][x]=df1['IMPORT VALUE CIF'][x]*df1['CNY'][x]\n",
    "       \n",
    "    elif(df1['CURRENCY'][x]=='AUD'):\n",
    "        df1['IMPORT_VALUE_CIF_USD'][x]=df1['IMPORT VALUE CIF'][x]*df1['AUD'][x]\n",
    "       \n",
    "    elif(df1['CURRENCY'][x]=='GBP'):\n",
    "        df1['IMPORT_VALUE_CIF_USD'][x]=df1['IMPORT VALUE CIF'][x]*df1['GBP'][x]\n",
    "       \n",
    "    elif(df1['CURRENCY'][x]=='EUR'):\n",
    "        df1['IMPORT_VALUE_CIF_USD'][x]=df1['IMPORT VALUE CIF'][x]*df1['EUR'][x]\n",
    "       \n",
    "    elif(df1['CURRENCY'][x]=='SGD'):\n",
    "        df1['IMPORT_VALUE_CIF_USD'][x]=df1['IMPORT VALUE CIF'][x]*df1['SGD'][x]\n",
    "        \n",
    "    elif(df1['CURRENCY'][x]=='VND'):\n",
    "        df1['IMPORT_VALUE_CIF_USD'][x]=df1['IMPORT VALUE CIF'][x]*df1['VND'][x]\n",
    "    \n",
    "    else:\n",
    "        df1['IMPORT_VALUE_CIF_USD'][x]='unidentified currency'\n",
    "       \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fff5363a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df1['IMPORT_VALUE_CIF_USD'].head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b7945e",
   "metadata": {},
   "source": [
    "# VOLUME CALCULATIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7446a1e5",
   "metadata": {},
   "source": [
    "1) Volume1-PCE: Directly pulling the data from quantity column - Assume it is all PCES FOR NOW <BR>\n",
    "2) Volume2-BOX: Quantity * Number of tests \n",
    "\n",
    "3) -ROUND IT TO TWO DECIMAL VALUES\n",
    "\n",
    "4)We have two volumes. Now  we need to check which one is correct based ond\n",
    "- Per Unit Weight\n",
    "- Per Unit Price\n",
    "\n",
    "\n",
    "5) PER UNIT GROSS WEIGHT\n",
    "\n",
    "Divide the Gross Weight / Volume1 <BR>\n",
    "Divide the Gross Weight / Volume2 <BR>\n",
    "\n",
    "6) PER UNIT NET WEIGHT<BR>\n",
    "Divide the NET Weight / Volume1<BR>\n",
    "Divide the NET Weight / Volume2<BR>\n",
    "\n",
    "\n",
    "7) PER UNIT PRICE<BR>\n",
    "DIVIDE THE IMPORT VALUE CIF (CONVERTED TO USD) / VOLUME1 <BR>\n",
    "DIVIDE THE IMPORT VALUE CIF (CONVERTED TO USD) / VOLUME2 <BR>\n",
    "\n",
    "\n",
    "8) Now we need to decide which volume do we need to consider. If we don't get anyone is correct\n",
    "then we have to go the manual check. \n",
    "\n",
    "9) WEIGHT RANGES: <BR>\n",
    "RANGE: 0.01 TO 0.03 - THIS IS THE NET WEIGHT <BR>\n",
    "RANGE: 0.01 TO 0.1 - THIS IS FOR THE GROSS WEIGHT<BR>\n",
    "\n",
    "\n",
    "10) PRICE\n",
    "RANGE: SHOULD BE <= TO $12 - one range only.\n",
    "\n",
    "put a count  - if you get 3 match we have 75% confidence\n",
    "we can fine tune this later\n",
    "put a count  - if you get 2 match we have 75% confidence\n",
    "put a count  - if you get 1 match we have 75% confidence\n",
    "\n",
    "Those which have 0 matches: these are put for the next stage now...\n",
    "\n",
    "For 100% WE WILL HAVE TO MATCH WITH THE MRL DATA. STRATEGY NEEDS TO BE DEVISED. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "15ce10d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Volume Calculations: \n"
     ]
    }
   ],
   "source": [
    "#1) Volume1-PCE: Directly pulling the data from quantity column - Assume it is all PCES FOR NOW\n",
    "#2) Volume2-BOX: Quantity * Number of tests\n",
    "print('Processing Volume Calculations: ')\n",
    "\n",
    "\n",
    "df1['test_quantity_final']=df1['test_quantity_final'].astype(float)\n",
    "df1['VOLUME1_PCE']=df1['QUANTITY']\n",
    "df1['VOLUME2_BOX']=df1['QUANTITY']*df1['test_quantity_final']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "44114e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PER UNIT GROSS WEIGHT - Volume1\n",
      "PER UNIT GROSS WEIGHT - Volume2\n"
     ]
    }
   ],
   "source": [
    "#PER UNIT GROSS WEIGHT\n",
    "\n",
    "print('PER UNIT GROSS WEIGHT - Volume1')\n",
    "print('PER UNIT GROSS WEIGHT - Volume2')\n",
    "\n",
    "#Divide the Gross Weight / Volume1\n",
    "df1['PER_PCE_GROSS_WEIGHT'] = df1['GROSS WEIGHT']/df1['VOLUME1_PCE']\n",
    "#Divide the Gross Weight / Volume2\n",
    "\n",
    "df1['PER_BOX_GROSS_WEIGHT'] = df1['GROSS WEIGHT']/df1['VOLUME2_BOX']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9e87c4c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PER UNIT NET WEIGHT - Volume1\n",
      "PER UNIT NET WEIGHT - Volume2\n"
     ]
    }
   ],
   "source": [
    "#PER UNIT NET WEIGHT\n",
    "print('PER UNIT NET WEIGHT - Volume1')\n",
    "print('PER UNIT NET WEIGHT - Volume2')\n",
    "\n",
    "#Divide the NET Weight / Volume1\n",
    "df1['PER_PCE_NET_WEIGHT'] = df1['NET WEIGHT']/df1['VOLUME1_PCE']\n",
    "\n",
    "#Divide the NET Weight / Volume2\n",
    "df1['PER_BOX_NET_WEIGHT'] = df1['NET WEIGHT']/df1['VOLUME2_BOX']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f9ef5a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PER UNIT PRICE - Volume1\n",
      "PER UNIT PRICE - Volume2\n"
     ]
    }
   ],
   "source": [
    "#7) PER UNIT PRICE\n",
    "print('PER UNIT PRICE - Volume1')\n",
    "print('PER UNIT PRICE - Volume2')\n",
    "\n",
    "#DIVIDE THE IMPORT VALUE CIF (CONVERTED TO USD) / VOLUME1\n",
    "df1['PER_PCE_UNIT_PRICE']=df1['IMPORT_VALUE_CIF_USD']/df1['VOLUME1_PCE']\n",
    "\n",
    "#DIVIDE THE IMPORT VALUE CIF (CONVERTED TO USD) / VOLUME2\n",
    "df1['PER_BOX_UNIT_PRICE']=df1['IMPORT_VALUE_CIF_USD']/df1['VOLUME2_BOX']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bcdf9f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Boolean checks for Net weight, Gross weight and Unit price - by Volume1 and Volume 2\n"
     ]
    }
   ],
   "source": [
    "#WEIGHT RANGES:\n",
    "#RANGE: 0.01 TO 0.03 - THIS IS THE NET WEIGHT\n",
    "\n",
    "print('Creating Boolean checks for Net weight, Gross weight and Unit price - by Volume1 and Volume 2')\n",
    "df1['NEW_QUANTITY_UNIT'] = np.empty((len(df1), 0)).tolist()\n",
    "\n",
    "df1['EQUAL_VOLUMES']=''\n",
    "df1['PCE_NET_WEIGHT_CHECK']=0\n",
    "df1['PCE_GROSS_WEIGHT_CHECK']=0\n",
    "\n",
    "df1['BOX_NET_WEIGHT_CHECK']=0\n",
    "df1['BOX_GROSS_WEIGHT_CHECK']=0\n",
    "\n",
    "df1['PCE_PRICE_CHECK']=0\n",
    "df1['BOX_PRICE_CHECK']=0\n",
    "\n",
    "counter=0\n",
    "\n",
    "\n",
    "for x in range(0,len(df1)):\n",
    "    if(df1['VOLUME1_PCE'][x]==df1['VOLUME2_BOX'][x]):\n",
    "        df1['EQUAL_VOLUMES'][x]=1\n",
    "    else:\n",
    "        df1['EQUAL_VOLUMES'][x]=0\n",
    "\n",
    "        \n",
    "    if(df1['PER_PCE_NET_WEIGHT'][x]>=0.01 and df1['PER_PCE_NET_WEIGHT'][x]<=0.03):\n",
    "        df1['PCE_NET_WEIGHT_CHECK'][x]='1'\n",
    "        counter=counter+1\n",
    "        df1['NEW_QUANTITY_UNIT'][x].append('PCE')\n",
    "        \n",
    "    if(df1['PER_BOX_NET_WEIGHT'][x]>=0.01 and df1['PER_BOX_NET_WEIGHT'][x]<=0.03):\n",
    "        df1['BOX_NET_WEIGHT_CHECK'][x]='1'\n",
    "        counter=counter+1\n",
    "        df1['NEW_QUANTITY_UNIT'][x].append('BOX')\n",
    "\n",
    "\n",
    "#RANGE: 0.01 TO 0.1 - THIS IS FOR THE GROSS WEIGHT\n",
    "\n",
    "    if(df1['PER_PCE_GROSS_WEIGHT'][x]>=0.01 and df1['PER_PCE_GROSS_WEIGHT'][x]<=0.1):\n",
    "        df1['PCE_GROSS_WEIGHT_CHECK'][x]='1'\n",
    "        counter=counter+1\n",
    "        df1['NEW_QUANTITY_UNIT'][x].append('PCE')\n",
    "        \n",
    "    if(df1['PER_BOX_GROSS_WEIGHT'][x]>=0.01 and df1['PER_BOX_GROSS_WEIGHT'][x]<=0.1):\n",
    "        df1['BOX_GROSS_WEIGHT_CHECK'][x]='1'\n",
    "        counter=counter+1\n",
    "        df1['NEW_QUANTITY_UNIT'][x].append('BOX')\n",
    "   \n",
    "    \n",
    "#WHATEVER IS THE MAJORITY THAT WILL BE THE QUANTITY UNIT \n",
    "\n",
    "#PRICE CHECK - 0.7 TO 12 USD\n",
    "\n",
    "    if(df1['PER_PCE_UNIT_PRICE'][x]>=0.7 and df1['PER_PCE_UNIT_PRICE'][x]<=12):\n",
    "        df1['PCE_PRICE_CHECK'][x]='1'\n",
    "        counter=counter+1\n",
    "        df1['NEW_QUANTITY_UNIT'][x].append('PCE')\n",
    "        \n",
    "    if(df1['PER_BOX_UNIT_PRICE'][x]>=0.7 and df1['PER_BOX_UNIT_PRICE'][x]<=12):\n",
    "        df1['BOX_PRICE_CHECK'][x]='1'\n",
    "        counter=counter+1\n",
    "        df1['NEW_QUANTITY_UNIT'][x].append('BOX')\n",
    "        \n",
    "    counter=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d13b4237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1807    [PCE, BOX, PCE, BOX, PCE, BOX]\n",
       "1808                                []\n",
       "1809                                []\n",
       "1810              [PCE, BOX, PCE, BOX]\n",
       "1811                                []\n",
       "Name: NEW_QUANTITY_UNIT, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['NEW_QUANTITY_UNIT'].tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29a2c60",
   "metadata": {},
   "source": [
    "# DATA QUALITY INDEX "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23b9e53",
   "metadata": {},
   "source": [
    "<b>When the Volume 1 equals Volume 2 </b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6af23791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigning correct quantity unit - PCE/BOX\n"
     ]
    }
   ],
   "source": [
    "print('Assigning correct quantity unit - PCE/BOX')\n",
    "df1['DQI']=''\n",
    "df1['QUANTITY_UNIT_FINAL']=np.nan\n",
    "\n",
    "\n",
    "df1['BOX_NET_WEIGHT_CHECK']=df1['BOX_NET_WEIGHT_CHECK'].astype(float)\n",
    "df1['BOX_GROSS_WEIGHT_CHECK']=df1['BOX_GROSS_WEIGHT_CHECK'].astype(float)\n",
    "df1['BOX_PRICE_CHECK']=df1['BOX_PRICE_CHECK'].astype(float)\n",
    "df1['PCE_NET_WEIGHT_CHECK']=df1['PCE_NET_WEIGHT_CHECK'].astype(float)\n",
    "df1['PCE_GROSS_WEIGHT_CHECK']=df1['PCE_GROSS_WEIGHT_CHECK'].astype(float)\n",
    "df1['PCE_PRICE_CHECK']=df1['PCE_PRICE_CHECK'].astype(float)\n",
    "\n",
    "df1['PCE_COUNT_IGNORE']=0\n",
    "\n",
    "\n",
    "for x in range(0,len(df1['EQUAL_VOLUMES'])):\n",
    "    if(df1['EQUAL_VOLUMES'][x]==1):\n",
    "        df1['PCE_COUNT_IGNORE'][x]=df1['PCE_NET_WEIGHT_CHECK'][x]+df1['PCE_NET_WEIGHT_CHECK'][x]+df1['PCE_PRICE_CHECK'][x]\n",
    "        \n",
    "       # print('EQUAL VOLUME: ',df1['EQUAL_VOLUMES'][x])\n",
    "       # print('net: ',df1['PCE_NET_WEIGHT_CHECK'][x])\n",
    "       # print('gross: ',df1['PCE_GROSS_WEIGHT_CHECK'][x])\n",
    "       # print('price',df1['PCE_PRICE_CHECK'][x])\n",
    "        df1['DQI'][x]=int(df1['PCE_NET_WEIGHT_CHECK'][x])+int(df1['PCE_GROSS_WEIGHT_CHECK'][x])+int(df1['PCE_PRICE_CHECK'][x])\n",
    "       # print('dqi: ',df1['DQI'][x])\n",
    "        if(df1['DQI'][x]!=0):\n",
    "            df1['QUANTITY_UNIT_FINAL'][x]='PCE'\n",
    "        elif(df1['DQI'][x]==0):\n",
    "            df1['DQI'][x]=0\n",
    "            df1['QUANTITY_UNIT_FINAL'][x]=''\n",
    "            df1['REQUIRES_MANUAL_VERIFICATION'][x]=1\n",
    "\n",
    "#WILL NEED MANUAL VERIFICATION FOR THE EMPTY ONE HERE......\n",
    "#There will be cases when the volumes are equal but we do not have any \n",
    "\n",
    "#CHECK THIS...\n",
    "#df1['PCE_NET_WEIGHT_CHECK']=df1['PCE_NET_WEIGHT_CHECK'].fillna(0)\n",
    "#df1['PCE_GROSS_WEIGHT_CHECK']=df1['PCE_GROSS_WEIGHT_CHECK'].fillna(0)\n",
    "\n",
    "#df1['BOX_NET_WEIGHT_CHECK']=df1['BOX_NET_WEIGHT_CHECK'].fillna(0)\n",
    "#df1['BOX_GROSS_WEIGHT_CHECK']=df1['BOX_GROSS_WEIGHT_CHECK'].fillna(0)\n",
    "\n",
    "#df1['PCE_PRICE_CHECK']=df1['PCE_PRICE_CHECK'].fillna(0)\n",
    "#df1['BOX_PRICE_CHECK']=df1['BOX_PRICE_CHECK'].fillna(0)\n",
    "\n",
    "#df1['DQI_COUNTER']=np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ee5fe1ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     \n",
       "1    0\n",
       "2    1\n",
       "3    0\n",
       "4     \n",
       "Name: DQI, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['DQI'].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449f6e7c",
   "metadata": {},
   "source": [
    "<b>When the Volume 1 and volume 2 are not equal </b> <br>\n",
    "1) Find the quantity unit \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "139f8d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64\n",
      "float64\n",
      "float64\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df1['BOX_COUNT_IGNORE']=0\n",
    "print(df1['BOX_COUNT_IGNORE'].dtype)\n",
    "\n",
    "\n",
    "\n",
    "for x in range(0,len(df1['EQUAL_VOLUMES'])):\n",
    "    if(df1['EQUAL_VOLUMES'][x]==0):\n",
    "        df1['PCE_COUNT_IGNORE'][x]=df1['PCE_NET_WEIGHT_CHECK'][x]+df1['PCE_NET_WEIGHT_CHECK'][x]+df1['PCE_PRICE_CHECK'][x]\n",
    "        \n",
    "        df1['BOX_COUNT_IGNORE'][x]=df1['BOX_NET_WEIGHT_CHECK'][x]+df1['BOX_GROSS_WEIGHT_CHECK'][x]+df1['BOX_PRICE_CHECK'][x]\n",
    "        \n",
    "        if (df1['PCE_COUNT_IGNORE'][x]>df1['BOX_COUNT_IGNORE'][x]):\n",
    "            df1['DQI'][x]=df1['PCE_COUNT_IGNORE'][x]\n",
    "            df1['QUANTITY_UNIT_FINAL'][x]='PCE'\n",
    "        \n",
    "        elif (df1['BOX_COUNT_IGNORE'][x] > df1['PCE_COUNT_IGNORE'][x]):\n",
    "            df1['DQI'][x]=df1['BOX_COUNT_IGNORE'][x]\n",
    "            df1['QUANTITY_UNIT_FINAL'][x]='BOX'\n",
    "            \n",
    "        elif (df1['PCE_COUNT_IGNORE'][x]==df1['BOX_COUNT_IGNORE'][x]):\n",
    "            df1['DQI'][x]=0\n",
    "            df1['QUANTITY_UNIT_FINAL'][x]='' \n",
    "            df1['REQUIRES_MANUAL_VERIFICATION'][x]=1\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "print(df1['BOX_NET_WEIGHT_CHECK'].dtype)\n",
    "print(df1['PCE_NET_WEIGHT_CHECK'].dtype)\n",
    "print(df1['PCE_PRICE_CHECK'].dtype)\n",
    "#NEED THE ADDITION OF MRL HERE..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a0a3b2",
   "metadata": {},
   "source": [
    "Based on this thought process, the proposed scale for Data Quality Index could be: <br>\n",
    "100%- columns of the product import transaction were logical and the price pertest or box was cross-checked against MRPL (maintaining the rows you’ve already marked as 100%) <br>\n",
    "75%- columns of the product import transaction were logical and the calculations made sense. We’re highly confident in this data but pricing info on MRPL was not available. <br>\n",
    "50% - columns of the product import transaction were generally logical but 1 field (aka column) didn’t make sense and therefore decreases our confidence in the validity of the TA transaction row <br>\n",
    "25%- columns of the product import transaction were somewhat logical, but had 2 fields (columns) that didn’t make sense so we really aren’t all that confident about the validity of the transaction row <br>\n",
    "0%- Columns of the product import transaction had 3 or more fields that didn’t make sense so we aren’t confident in the transaction row <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "39769c49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    1\n",
       "3    0\n",
       "4    0\n",
       "Name: DQI, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['DQI'].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f57392b",
   "metadata": {},
   "source": [
    "# Filtration of RDT AND NON RDT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6cc2fc",
   "metadata": {},
   "source": [
    "Now select \"SARS-CoV-2 Antigen Rapid Diagnostic Tests\" and \"SARS-CoV-2 Antibody Rapid Diagnostic Tests\" from Test Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f015f041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering RDT tests\n"
     ]
    }
   ],
   "source": [
    "print('Filtering RDT tests')\n",
    "df1=df1[(df1['Test_Type']=='SARS-CoV-2 Antigen Rapid Diagnostic Tests') | (df1['Test_Type']=='SARS-CoV-2 Antibody Rapid Diagnostic Tests')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0b70b615",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df1.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5759120f",
   "metadata": {},
   "source": [
    "# SAVING THE FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "43b71791",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1.to_csv('Accuracy_Number_Of_Test2.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "83bd6e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#r = re.compile(r'([0-9]+X[0-9]+T+|[0-9]+\\*[0-9]+T|[0-9]+\\*[0-9]+ T|[0-9]+X[0-9]+ T+)')\n",
    "#ANSWER=r.search('YHLO IFLASH SARS-COV-2 IGM DUS,KIT 2*50 TES')\n",
    "#if(ANSWER):\n",
    "#    print('yes')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "71988d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using regex to identify Values like 2*50 and 2X50\n",
    "#r = re.compile(r'([0-9]+X[0-9]+|[0-9]+\\*[0-9])')\n",
    "\n",
    "#for x in range(0,len(df1)):\n",
    "#    if(r.search(df1['PRODUCT DETAILS'][x])):\n",
    "#        print('True - Index: ',x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85306998",
   "metadata": {},
   "source": [
    "# REFERENCE TO MRL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a7ba2e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading MRL File\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Source: GF',\n",
       " 'Source: Path',\n",
       " 'FIND- Antigens (Dev/Under Eval)',\n",
       " 'Type of Test',\n",
       " 'Unique Identifier',\n",
       " 'Merged Unique ID',\n",
       " 'Manufacturer Product Catalogue number',\n",
       " 'Product Name\\n(IVD product)',\n",
       " 'Product name- Special characters removed',\n",
       " 'product_keywords',\n",
       " 'Reference detail',\n",
       " 'Manufacturer',\n",
       " 'manufacturer_keywords',\n",
       " 'Manufacturer HQ location- PATH',\n",
       " 'Manufactuer location- ADP ',\n",
       " 'Manufacturer HQ location- FIND',\n",
       " 'Consolidated HQ Manufacturer Location (PATH Manufactuer HQ & ADP Manufacturer HQ)',\n",
       " 'Phase ',\n",
       " 'SRA Approval',\n",
       " 'Total SRA Criteria Eligibility ',\n",
       " 'Comments ',\n",
       " 'EXPIRED ',\n",
       " 'CE-IVD ',\n",
       " 'US FDA EUA (US Food and Drug Administration Emergency Use Authorization) ',\n",
       " 'EUA expiry?',\n",
       " 'Health Canada/Interim Order',\n",
       " 'WHO EUL (Emergency Use Listing)',\n",
       " 'PMDA (Pharmaceuticals and medical devices agency)',\n",
       " 'TGA (Therapeutic Goods Administration)',\n",
       " 'IFU Link',\n",
       " 'IFU Link ',\n",
       " 'IFU Link (Research)',\n",
       " ' IFU link Combined sources [Info from Column P&Q] (IFU links from ADP COVID-19 DPR & PATH)',\n",
       " 'Global Fund-Reference price per pack EXW, USD',\n",
       " 'ADP- Indicative purchase pricing (per test)',\n",
       " 'Global Fund- Reference price per test EXW, USD',\n",
       " 'Consolidated price per test (Global Fund- Reference price per test + ADP- Indicative purchase pricing (per test)',\n",
       " 'Pakistan Merged ID',\n",
       " 'India Merged ID',\n",
       " 'Indonesia Merged ID',\n",
       " 'South Africa Merged ID',\n",
       " 'Philippines Merged ID',\n",
       " 'TA-Indonesia']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#READ THE MRL FILE \n",
    "print('Reading MRL File')\n",
    "mrl=pd.read_excel(\"C:/Users/DrC/Desktop/Eureka Idea Co/Number of Test Testing File/Master reference list V2 CD.xlsx\",sheet_name='Master Sheet 3.0-Deduped',header=1)\n",
    "mrl.head(5)\n",
    "list(mrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "95368bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1_mrl = pd.merge(df1, mrl, left_on='PRODUCT DETAILS',right_on='Product Name\\n(IVD product)',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a3738598",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1_mrl['Product Name\\n(IVD product)'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6f124dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for x in range(0,len(df1_mrl)):\n",
    "#    if(df1_mrl['PRODUCT DETAILS'][x]==df1_mrl['Product Name\\n(IVD product)'][x]):\n",
    "#        df1_mrl['UNIQUE_ID'][x]=df1_mrl['Unique Identifier'][x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b9d9dc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1_mrl['UNIQUE_ID'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb5249a",
   "metadata": {},
   "source": [
    "# Cleaning the PRODUCT DETAILS FOR MATCHING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9e77b090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing product details in MRL for matching\n"
     ]
    }
   ],
   "source": [
    "print('Preparing product details in MRL for matching')\n",
    "df1['PDC_NEW_DF']=df1['PRODUCT DETAILS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b1896b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['PDC_NEW_DF']= df1['PDC_NEW_DF'].str.strip() \n",
    "df1['PDC_NEW_DF'] = df1['PDC_NEW_DF'].str.replace(r'[^\\w\\s]+', '') \n",
    "#Removing double spaces between the words\n",
    "df1['PDC_NEW_DF']= df1['PDC_NEW_DF'].replace('\\s+', ' ', regex=True)\n",
    "df1['PDC_NEW_DF']=df1['PDC_NEW_DF'].str.upper()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01dce049",
   "metadata": {},
   "source": [
    "# Cleaning the Product Name\\n(IVD product FROM MRL FOR MATCHING\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "969e685a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mrl['PDC_NEW_MRL']=mrl['Product Name\\n(IVD product)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1f04a063",
   "metadata": {},
   "outputs": [],
   "source": [
    "mrl['PDC_NEW_MRL']= mrl['PDC_NEW_MRL'].str.strip() \n",
    "mrl['PDC_NEW_MRL'] = mrl['PDC_NEW_MRL'].str.replace(r'[^\\w\\s]+', '') \n",
    "#Removing double spaces between the words\n",
    "mrl['PDC_NEW_MRL']= mrl['PDC_NEW_MRL'].replace('\\s+', ' ', regex=True)\n",
    "mrl['PDC_NEW_MRL']=mrl['PDC_NEW_MRL'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ab84acd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a column with close matches between product details in Trade Atlas and MRL.\n",
      "This step shall take a while. Please be patient.\n",
      "Matches completed\n"
     ]
    }
   ],
   "source": [
    "# https://www.statology.org/fuzzy-matching-pandas/\n",
    "\n",
    "print('Creating a column with close matches between product details in Trade Atlas and MRL.\\nThis step shall take a while. Please be patient.')\n",
    "import difflib \n",
    "\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "mrl['product_match'] = mrl['PDC_NEW_MRL']\n",
    "\n",
    "#convert product_name_mrl in mrl to product name it most closely matches in df1\n",
    "\n",
    "mrl['PDC_NEW_MRL'] = mrl['PDC_NEW_MRL'].apply(lambda x: (difflib.get_close_matches(x, df1['PDC_NEW_DF'])[:1] or [None])[0])\n",
    "#df2['Unit'] = df2['Unit'].apply(lambda x: (difflib.get_close_matches(x, df1['Unit'])[:1] or [None])[0])\n",
    "\n",
    "#https://stackoverflow.com/questions/36557722/python-pandas-difflib-throws-list-index-out-of-range-error\n",
    "\n",
    "#convert team name in df2 to team name it most closely matches in df1\n",
    "print('Matches completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9db380d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                               None\n",
       "1                                               None\n",
       "2                SARCOV2 AG RAPID TEST CASSETTE BAIK\n",
       "3           SARSCOV2 ANTIGEN TEST KIT COLLOIDAL GOLD\n",
       "4       SARSCOV2 ANTIGEN SALIVA RAPID TEST KIT 1TBOX\n",
       "                            ...                     \n",
       "1376                                            None\n",
       "1377                         HUMASIS COVID19 AG TEST\n",
       "1378                         LIAISON SARSCOVS1S2 IGG\n",
       "1379             RAPID SARSCOV2 ANTIBODY IGMIGG TEST\n",
       "1380    PREVENT COVID 19 ANTIGEN SWAB NASOPHARINGEAL\n",
       "Name: PDC_NEW_MRL, Length: 1381, dtype: object"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrl['PDC_NEW_MRL']\n",
    "\n",
    "#merge the DataFrames into one\n",
    "#new = df1.merge(mrl)\n",
    "#view final DataFrame\n",
    "#print(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f45c6de6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "745"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b75d8d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a key in df1\n",
    "df1['MERGE_KEY']=''\n",
    "\n",
    "for x in range(0,len(df1)):\n",
    "    df1['MERGE_KEY'][x]=x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a32054f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1.to_csv('check4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "92f8e3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_mrl = pd.merge(df1, mrl, left_on='PDC_NEW_DF',right_on='PDC_NEW_MRL',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b45b2ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1_mrl[['PDC_NEW_MRL', 'PDC_NEW_DF']].tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "88654abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_mrl['PDC_NEW_DF']=df1_mrl['PDC_NEW_DF'].astype(str)\n",
    "df1_mrl['PDC_NEW_MRL']=df1_mrl['PDC_NEW_MRL'].astype(str)\n",
    "df1_mrl['product_match']=df1_mrl['product_match'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1a35255f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing the match percentage between Product detail (Trade Atlas) and Product Details (MRL)...\n"
     ]
    }
   ],
   "source": [
    "print('Analyzing the match percentage between Product detail (Trade Atlas) and Product Details (MRL)...')\n",
    "from difflib import SequenceMatcher\n",
    "#df1['MATCH'] = np.empty((len(df1), 0)).tolist()\n",
    "df1_mrl['MATCH_PERCENT']=''\n",
    "for x in range(0,len(df1_mrl)):\n",
    "    df1_mrl['MATCH_PERCENT'][x]= SequenceMatcher(None, df1_mrl['PDC_NEW_DF'][x], df1_mrl['product_match'][x]).ratio()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c1e80f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1_mrl.to_csv('Cross_reference.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "388a8fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1_mrl['MATCH_PERCENT']\n",
    "#df1_mrl[['MERGE_KEY','MATCH_PERCENT']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cd68d8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1_mrl['MERGE_KEY'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "04301ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df=df1_mrl.groupby(['MERGE_KEY'])['MATCH_PERCENT'].max().reset_index() #finding the index and maximum value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a5f6d22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df=pd.merge(df1_mrl, grouped_df, on=['MERGE_KEY', 'MATCH_PERCENT']) #By Default it is inner join."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "284bf210",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(grouped_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c349f7",
   "metadata": {},
   "source": [
    "#If a match is found, then put the MRPL Unique ID in Column MRL Unique ID (BP). \n",
    "#Need to be more careful about searching the product names, sometimes, there is not an exact match\n",
    "#(Matching every character) with the products in the MRL. \n",
    "#We need to search a part of the name or match the Exporter's name in TA with the Manufacturer's name in MRL.\n",
    "\n",
    "\n",
    "#MATCH THE EXPORTERS NAME WITH THE MANUFACTURER NAME\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfade313",
   "metadata": {},
   "source": [
    "# MRL CHECK BOOLEAN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "31baf519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating MRL Boolean Check\n"
     ]
    }
   ],
   "source": [
    "print('Creating MRL Boolean Check')\n",
    "grouped_df['MRL_CHECK']=0\n",
    "for x in range(0,len(grouped_df)):\n",
    "    if(grouped_df['MATCH_PERCENT'][x]>=0.70):\n",
    "        grouped_df['MRL_CHECK'][x]=1\n",
    "    else:\n",
    "        grouped_df['MRL_CHECK'][x]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "37fb1120",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now these are not duplicates. It is possible that a product in the trade atlas matches with two products in the MRL with the same \n",
    "#Match percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "77215aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(grouped_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ddcbc0",
   "metadata": {},
   "source": [
    "# DEFINING THE DQI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "85e30f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing the Data Quality Index\n"
     ]
    }
   ],
   "source": [
    "print('Analyzing the Data Quality Index')\n",
    "for x in range(0,len(grouped_df)):\n",
    "    grouped_df['DQI'][x]=grouped_df['PCE_NET_WEIGHT_CHECK'][x]+grouped_df['PCE_GROSS_WEIGHT_CHECK'][x]+grouped_df['PCE_PRICE_CHECK'][x] +grouped_df['MRL_CHECK'][x]\n",
    "    \n",
    "\n",
    "grouped_df['DQI_FINAL']=''    \n",
    "\n",
    "for x in range(0,len(grouped_df)):\n",
    "    if(grouped_df['DQI'][x]==0):\n",
    "        grouped_df['DQI_FINAL'][x]= '0'\n",
    "    elif(grouped_df['DQI'][x]==1):\n",
    "        grouped_df['DQI_FINAL'][x]= '25'\n",
    "    elif(grouped_df['DQI'][x]==2):\n",
    "        grouped_df['DQI_FINAL'][x]= '50'\n",
    "    elif(grouped_df['DQI'][x]==3):\n",
    "        grouped_df['DQI_FINAL'][x]= '75'\n",
    "    elif(grouped_df['DQI'][x]==4):\n",
    "        grouped_df['DQI_FINAL'][x]= '100'\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "72834503",
   "metadata": {},
   "outputs": [],
   "source": [
    "#grouped_df['DQI_FINAL']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adafc8ca",
   "metadata": {},
   "source": [
    "# NEW THINGS THAT NEEDS TO BE DONE "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef645ea5",
   "metadata": {},
   "source": [
    "<b>if there is a match between product detail and MRL then pull the MRL UNIQUE NUMBER - DONE</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1bfdada6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pulling MRL Unique Number\n"
     ]
    }
   ],
   "source": [
    "print('Pulling MRL Unique Number')\n",
    "grouped_df['UNIQUE_ID_PULL']=''\n",
    "for x in range(0,len(grouped_df)):\n",
    "    if(grouped_df['MRL_CHECK'][x]==1):\n",
    "        grouped_df['UNIQUE_ID_PULL'][x]=grouped_df['Unique Identifier'][x]\n",
    "    \n",
    "#list(mrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6c53d53d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boolean check for Unit price match between MRL Unit Price and calculated Unit price\n"
     ]
    }
   ],
   "source": [
    "#If we get a match in MRL for the product, then need to match the unit price (if it is available in MRL). If we get a similar unit price, then we can say 100% Confidence.\n",
    "\n",
    "print('Boolean check for Unit price match between MRL Unit Price and calculated Unit price')\n",
    "#grouped_df['Global Fund-Reference price per pack EXW, USD']=grouped_df['Global Fund-Reference price per pack EXW, USD'].round(2)\n",
    "#grouped_df['ADP- Indicative purchase pricing (per test)']=grouped_df['ADP- Indicative purchase pricing (per test)'].round(2)\n",
    "#grouped_df['Global Fund- Reference price per test EXW, USD']=grouped_df['Global Fund- Reference price per test EXW, USD'].round(2)\n",
    "#grouped_df['Consolidated price per test (Global Fund- Reference price per test + ADP- Indicative purchase pricing (per test)']=grouped_df['Consolidated price per test (Global Fund- Reference price per test + ADP- Indicative purchase pricing (per test)'].round(2)\n",
    "\n",
    "#If there is a match and if any of the value matches the price, then I say we have a match. This deals with the different pricing issue. Different pricing makes the MRL list invalid initself.\n",
    "grouped_df['UNIT_PRICE_MATCH']=''\n",
    "for x in range(0,len(grouped_df)):\n",
    "    if(grouped_df['QUANTITY_UNIT_FINAL'][x]=='PCE'):\n",
    "        if((grouped_df['PER_PCE_UNIT_PRICE'][x]==grouped_df['Global Fund-Reference price per pack EXW, USD'][x]) \n",
    "          | (grouped_df['PER_PCE_UNIT_PRICE'][x]==grouped_df['ADP- Indicative purchase pricing (per test)'][x]) | (grouped_df['PER_PCE_UNIT_PRICE'][x]==grouped_df['Global Fund- Reference price per test EXW, USD'][x]) |\n",
    "          (grouped_df['PER_PCE_UNIT_PRICE'][x]==grouped_df['Consolidated price per test (Global Fund- Reference price per test + ADP- Indicative purchase pricing (per test)'][x])):\n",
    "            grouped_df['UNIT_PRICE_MATCH'][x]=1\n",
    "            \n",
    "    if(grouped_df['QUANTITY_UNIT_FINAL'][x]=='BOX'):\n",
    "        if((grouped_df['PER_BOX_UNIT_PRICE'][x]==grouped_df['Global Fund-Reference price per pack EXW, USD'][x]) \n",
    "        | (grouped_df['PER_BOX_UNIT_PRICE'][x]==grouped_df['ADP- Indicative purchase pricing (per test)'][x]) | (grouped_df['PER_BOX_UNIT_PRICE'][x]==grouped_df['Global Fund- Reference price per test EXW, USD'][x]) |\n",
    "        (grouped_df['PER_BOX_UNIT_PRICE'][x]==grouped_df['Consolidated price per test (Global Fund- Reference price per test + ADP- Indicative purchase pricing (per test)'][x])):\n",
    "            grouped_df['UNIT_PRICE_MATCH'][x]=1\n",
    "\n",
    "\n",
    "#The prices are empty for the majority of the rows in the MRL. should this step be included? \n",
    "\n",
    "# 'PER_PCE_UNIT_PRICE'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "43dde3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#grouped_df['Global Fund-Reference price per pack EXW, USD'].value_counts()\n",
    "#grouped_df['ADP- Indicative purchase pricing (per test)'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d69dbbee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Performing Boolean check for Number of tests match between MRL and Trade Atlas \n"
     ]
    }
   ],
   "source": [
    "#Create a new column, modification of reference detail.\n",
    "print(' Performing Boolean check for Number of tests match between MRL and Trade Atlas ')\n",
    "\n",
    "r = re.compile(r'([0-9]+X[0-9]+T+|[0-9]+\\*[0-9]+T|[0-9]+\\*[0-9]+ T|[0-9]+X[0-9]+ T+)')\n",
    "grouped_df['REFERENCE_DETAIL_CLEAN']=''\n",
    "grouped_df['REFERENCE_DETAIL_CLEAN']=grouped_df['REFERENCE_DETAIL_CLEAN'].astype(str)\n",
    "grouped_df['Reference detail']=grouped_df['Reference detail'].astype(str)\n",
    "grouped_df['REFERENCE_DETAIL_MATCH']=''\n",
    "\n",
    "#1) If there is a patter like x then store that value\n",
    "\n",
    "for x in range(0,len(grouped_df)):\n",
    "    if(r.search(grouped_df['Reference detail'][x])):\n",
    "        grouped_df['REFERENCE_DETAIL_CLEAN'][x]='' #find all gets the number as it is \n",
    "    else:\n",
    "        grouped_df['REFERENCE_DETAIL_CLEAN'][x]=re.sub(\"[^0-9]\",\"\", grouped_df['Reference detail'][x])\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "#r.findall(grouped_df['Reference detail'][x])  THIS IS IMPORTANT AS IT GETS THE VALUE FOR US        \n",
    "#This below code is a problem but is important\n",
    "#elif(int(re.sub(\"[^0-9]\", \"\", grouped_df['Reference detail'][x]))>=5 and int(re.sub(\"[^0-9]\", \"\", grouped_df['Reference detail'][x]))<=2500):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929639fa",
   "metadata": {},
   "source": [
    "<b>PROBLEM IDENTIFIED: WHAT TO DO FOR REFERENCE DETAIL WITH THE VALUE: 24T/kit 48T/kit 96T/kit </b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cfe81cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df['REFERENCE_DETAIL_CLEAN']=grouped_df['REFERENCE_DETAIL_CLEAN'].replace('',np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "22233596",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(grouped_df['REFERENCE_DETAIL_CLEAN'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1ab60b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare the quantity with the extracted number of test.\n",
    "#if the quantity is equal then Reference Detail Match = 1 \n",
    "grouped_df['REFERENCE_DETAIL_CLEAN']=grouped_df['REFERENCE_DETAIL_CLEAN'].astype(float)\n",
    "#matching reference detail clean with the the test quantity final..         \n",
    "for x in range(0,len(grouped_df)):\n",
    "    if(grouped_df['test_quantity_final'][x]==grouped_df['REFERENCE_DETAIL_CLEAN'][x]):\n",
    "        grouped_df['REFERENCE_DETAIL_MATCH'][x]=1\n",
    "        \n",
    "    else:\n",
    "        grouped_df['REFERENCE_DETAIL_MATCH'][x]=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "12cad063",
   "metadata": {},
   "outputs": [],
   "source": [
    "#grouped_df[['test_quantity_final','REFERENCE_DETAIL_CLEAN','REFERENCE_DETAIL_MATCH']].loc[125:135,]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0642058",
   "metadata": {},
   "source": [
    "<b>if there are two matches then select the one whose Manufacturer matches with the exporter name</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "261a1c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if there is a duplicate then I have set the "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a183482",
   "metadata": {},
   "source": [
    "# Removing duplicates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a90d3a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing duplicates in the Trade Atlas and MRL product match\n"
     ]
    }
   ],
   "source": [
    "print('Removing duplicates in the Trade Atlas and MRL product match')\n",
    "grouped_df=grouped_df.drop_duplicates(subset='MERGE_KEY').reset_index(drop=True) #removing the duplicated IDS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3965af19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting file\n"
     ]
    }
   ],
   "source": [
    "print('Exporting file')\n",
    "grouped_df.to_csv('OUTPUT1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "066e3da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed\n"
     ]
    }
   ],
   "source": [
    "print('completed')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
